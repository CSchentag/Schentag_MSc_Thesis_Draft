\chapter{Background} \label{bkgnd}

\section{Limb Imaging \& The Atmosphere}
This section provides an overview of the atmosphere, specifically the upper troposphere/lower stratosphere (UTLS) region that the LIFE instrument is designed to measure. This region is discussed in detail, with topics including the species found in both the troposphere and stratosphere, mixing of these regions that form the UTLS region, and the lack of measurements. This section will also discuss atmospheric limb remote sensing, including different methods as well as instruments that have been important to this field.

\subsection{UTLS Overview}
The atmosphere of Earth is divided into several layers, according to its thermal structure. The two lowest layers, the troposphere and stratosphere, are described here as they are most relevant to the LIFE instrument. Described here are also the main constituents of interest to LIFE: Methane (CH\textsubscript{4}), Water Vapour (H\textsubscript{2}O), Ozone (O\textsubscript{3}), and Nitrous Oxide (N\textsubscript{2}O). Finally an overview is given of the region between these two layers, known as the UTLS, the measurement region of the LIFE instrument.

\subsubsection{Troposphere \& Stratosphere Species}
From ground level up to roughly 10 km, temperature decreases steadily. This region is known as the troposphere, and its temperature is dependent on surface heating from Earth, and as such as the altitude increases the temperature decreases. The upper boundary of this region is known as the tropopause, marked by a temperature minimum. This boundary is typically 10 km but is different depending on the geographic region, such as the tropics, where the boundary can be as high as 17 km~\citep{ext_utls}. This is the region where most weather occurs, and as a result it is continuously being cleaned by of aerosols via cloud droplets, falling to the ground as rain. This region is also quite turbulent, leading to a generally well mixed region of gases and aerosols. Through this region, the concentrations of long-lived atmospheric constituents such as O\textsubscript{2} and N\textsubscript{2} are relatively uniform and independent of height, due to mixing caused by the turbulence~\citep{atmos_phys_and_climate}.

Above the tropopause is the stratosphere, which covers the region from roughly 15 km to 50 km, and is characterized by an increase in temperature. This temperature increase continues until the stratopause, the region between the stratosphere and mesosphere, where there is a temperature maximum. This temperature is a result of the ozone layer that is in this region, and its resulting ozone heating. The warming in the stratosphere causes an important difference between the stratosphere and troposphere, which is that there is very little mixing in this region. Unlike the troposphere, where a decrease in temperature causes turbulence, the stratosphere is relatively calm and as a result there is a less homogeneous mix of constituents in this region, such as the ozone layer~\citep{atmos_science}. Figure \ref{fig:atm_layers} shows a temperature and pressure profile of the atmosphere (measured by the OSIRIS instrument) with the atmospheric layers, as well as the upper troposphere/lower stratosphere region of interest.

 \begin{figure}
\centering
  \includegraphics[width=\linewidth]{chap2_images/atmospheric_layers.JPG}
  \caption{Atmospheric layers with a pressure and temperature profile from the OSIRIS instrument. The upper troposphere/lower stratosphere region is shaded grey.}
  \label{fig:atm_layers}
\end{figure}

 This has a large affect on one of the constituents measured by LIFE, methane (CH\textsubscript{4}. As a long-lived gas, methane can remain in the troposphere for a long period and become well-mixed. If it travels upwards to the stratosphere, it will become oxidized. As a result, methane decreases steadily in as altitude increases in the stratosphere. The oxidation of methane leads to water vapour, an important greenhouse gas. Methane also plays a major role in the atmosphere as a greenhouse gas, which has increased exponentially in the last few hundred years as a result of human activities such as farming~\citep{atmos_phys_and_climate}. 

Similar to methane, nitrous oxide is a long-lived constituent and as such is well-mixed in the tropopause. It comes from a variety of sources from bacterial process to human process of fossil fuel combustion. In the stratosphere, it decreases with altitude, disassociating into NO. NO is important to study as it can cause the destruction of ozone, and has played a role in the thinning of the ozone layer. It is also a greenhouse gas and plays a role in climate change~\citep{atmos_phys_and_climate}.

Ozone is a atmospheric species mainly concentrated in the stratosphere, in the ozone layer. Below the stratosphere, it is quickly destroyed through oxidation or will be absorbed due to its water-solubility. It is important to study, as it is essential to life on Earth due to its absorption of UV rays. As it absorbs IR radiation, it also plays a role in climate change as a greenhouse gas~\citep{atmos_phys_and_climate}. The majority of ozone being concentrated in the lower stratosphere as the ozone layer, it is within the area of interest for the LIFE instrument and is studied with measurements in this region.

In the low troposphere, water vapour is abundant, and is perhaps one of the most important atmospheric species to study. Due to its strong absorptive of IR radiation it is an extremely important greenhouse and plays a major role in climate change. It is unlikely to reach the stratosphere due to condensation at higher altitudes as temperature decreases, where it falls as rain or snow. If it does reach the stratosphere, it often dissociates to the free radical OH, which can damage to the ozone layer~\citep{atmos_phys_and_climate}. These results of these processes are measured by the LIFE instrument for study.

\subsubsection{The UTLS} \label{UTLS}
Now that the troposphere and stratosphere are described, the region that is of most interested to this thesis and the LIFE instrument is discussed: The upper troposphere/lower stratosphere region. This part of the atmosphere is roughly defined as the region $\pm$5 km around the boundary between the troposphere and stratosphere. This region is important to study for a number of reasons. The tropospheric and stratospheric regions have very different processes, and as a result the boundary between these regions has a large affect on the chemistry of both. The exchange between the two is known as the \textit{Stratosphere-troposphere exchange (STE)}~\citep{ext_utls}.

The STE is part of the atmospheric circulation that moves air, pollutants, and other constituents from the troposphere to the stratosphere. The air movement is largely due to the surface heating the air, so it rises. As a result the convection and movement of air is strongest around the tropics, where the air is the warmest for most of the year~\citep{STE_text}. It cools in the UTLS region and moves toward the poles, where it falls again. This is an important process to study, as the movement of chemical constituents across this layer has direct effects on chemicals in the atmosphere, such as ozone. The destruction of ozone as well as the greenhouse gases that travel to the stratosphere via STE means that this process and the UTLS region have a critical role in studying climate change.
% Is an image of the STE useful here?
Research has shown that the STE has direct implications on atmospheric ozone. Specifically, the destruction of ozone in the stratosphere (the ozone layer) and an increase in tropospheric ozone. As mentioned previously, nitrous oxide can travel upwards through the stratosphere and disassociate to NO, which is a free radical. This can combine with ozone to form NO\textsubscript{x}, causing a thinning of the ozone layer in the stratosphere. Likewise, water vapour that rises to the stratosphere can disassociate to OH, a free radical similar to NO with the same ability to combine with ozone and cause damage to the ozone layer~\citep{WMO_ozone}. Water vapour and ozone are particularly sensitive to the rise and fall of air in this region due to their steep gradients in both regions (the water vapour nearer to earth and the concentrated ozone layer)~\citep{GLORIA_objectives}. As air travels downwards via STE, it carries down much of the pollutants that can affect the ozone layer, but can carry ozone into the troposphere as well. Ozone in the troposphere can have large affects on both air quality and climate change, as a greenhouse gas. Thus, the STE plays a major role in climate change, as greenhouse gases are moved between these two layers where they have different effects~\citep{STE_text}~\citep{UTLS_STE}.

Due to the impact of chemical exchanges between the tropospheric and stratospheric layers, variability and changes to the UTLS are important in studying climate change. Changes to greenhouse gases such as ozone or water vapour in either of these regions have significant effects on chemical balance and IR absorption, leading to climate change~\citep{climate_change_2007}. In addition to this, the temperature minimum in the tropopause causes the region to be a key part of IR radiation escaping from the tropopause to space, further effecting surface climate and the climate feedback system~\citep{ext_utls}. It is clear that this region must be adequately measured to further research climate change.

These process have been measured and studied, but not in depth. Simulations and models have been created of this region, but there is large amounts of uncertainty. Some models have shown that with even small uncertainties in the exchange and processes of trace gases in the UTLS region, there is a significant affect on estimated concentrations of species such as ozone and water vapour. As a result, the radiative effects that are to be studied are highly uncertain. Measurements must then be improved of these gases in the UTLS. A major instrument in this area, MIPAS, took measurements from a satellite platform but with low spatial resolution. A gap is identified in trace gas measurements in the UTLS that will help inform simulations of the region. The GLORIA instrument was the first to provide insight into this region with multiple two and three dimensional measurements with high spatial resolution~\citep{GLORIA_objectives}. LIFE is designed to follow in the GLORIA instrument footsteps in measuring this region using similar limb imaging methods via Fourier transform spectrometer. Both the GLORIA and MIPAS instruments are described in Section \ref{instruments} as forerunners to the LIFE project. GLORIA, MIPAS, and LIFE all use limb-emission imaging to take measurements; an overview of limb imaging is provided in the section below.

\subsection{Techniques} \label{techniques}
There are many atmospheric measuring techniques, that can initially be split into two groups: Passive and active sensing. Active sensing techniques involve emitting high-energy radiation to detect its reflection to perform measurements, for example LIDARs. However, most instruments that measure in the troposphere/stratosphere region that is of interest are passive, balloon-borne or satellite borne instruments. Passive instruments can also be split into two groups: Nadir-sounding and Limb-sounding. Nadir-sounding instruments have downwards pointing geometry, and are useful for tropospheric measurements that have a high horizontal resolution. Limb-sounders look tangentially through the atmosphere, or the \textit{limb}. This method is useful for stratospheric measurements, where the constituents are less dense; with the long ray path of this method, the lower troposphere may saturate measurements due to cloud cover. This method can also provide good vertical resolution, depending on the instrument~\citep{SPARC}. An example of a limb-sounding instrument is shown in Figure \ref{fig:limb_emission_geometry}. Depending on what the instrument is scanning through the atmosphere, limb measurements are classified into four major groups: solar occultation, stellar occultation, limb scattering, and limb emission.

 \begin{figure}
\centering
  \includegraphics{chap2_images/Limb_emission_geometry_example.JPG}
  \caption{Limb emission observation example. For solar or stellar occultation, the sun or stars would be at the end of the LOS, respectively.}
  \label{fig:limb_emission_geometry}
\end{figure}

\subsubsection{Solar \& Stellar Occultation}
Solar occultation measurements are made by looking through the atmospheric limb at the atmosphere at the sun. The radiance emitted by the sun and attenuated by the atmosphere through absorption or scattering is measured. This method allows for altitude resolved measurements as the satellite orbits the Earth~\citep{SPARC}. SAGE II, a solar occulatation measurement taken as an example, begins taking measurements at tangent height of 150 km, and continues until the sun is obscured by clouds or is below the horizon. This particular system for SAGE II worked well as at a height of 150 km there is very little attenuation, allowing a self calibration process at lower tangent heights against 150 km~\citep{SAGEII_solar_occultation}. An issue with this method is the lack of freedom in measurement geometry, as it is defined as the position of the sun. This leads to reduced data density compared to emission-sounding instruments, as the instrument can only take images at sunrise or sunset~\citep{SPARC}. In the case of SAGE II, it took measurements 30 times per day, 15 per sunrise or sunset. Through a number of orbits however, this eventually leads to global coverage~\citep{SAGEII_solar_occultation}. However, although the data density is lower than other options, the radiance signal due to imaging towards the sun is much stronger than emission or scattering imaging, and allows for very precise measurements. Measurements from solar occultation are usually in the UV to mid-IR wavelength range~\citep{SPARC}. Some instrument examples of this method include the ACE-FTS and SAGE I, II and III instruments, which primarily examined ozone but have also measured other species such as water vapour and nitrogen dioxide in the case of SAGE III~\citep{ACE_FTS}~\citep{SAGEI_and_II}~\citep{SAGE_III}.

Stellar occultation is similar to solar occultation, except the radiance from stars is measured instead. The advantage of this method over solar occultation is the greater data density that can be achieved as there is a larger time period for measuring stellar radiance over solar radiance, which is just at sunrise and sunset. This method can be used during both daytime and nighttime for even higher data density, but daytime measurements are typically of lower quality as the signal caused by the sun can interfere with the stellar measurements~\citep{SPARC}. The GOMOS (Global Ozone Monitoring by Occultation of Stars) instrument is an example of a stellar occultation instrument, which measures a number of species but chiefly ozone. The good global coverage and measurement time of stellar occultation allows GOMOS to take 400-600 occultation measurements in 24 hours, with data being taken in both daytime and nighttime~\citep{GOMOS_stellar_occulation}. This instrument, and most stellar occultation instruments measure in the spectral range of 1\textmu m, due to thermal emission interference at longer wavelengths~\citep{SPARC}.

\subsubsection{Limb Scattering}
Another method of limb-sounding is to measure scattered photons from the sun. These photons are scattered into the FOV of the instrument, which provides information on the atmosphere either by the scattering itself or the absorption of photos through the atmosphere. The requirement for this method is that to take measurements in the daytime, since the sun is the source~\citep{SPARC}. An example of limb scattering is the SCIAMACHY instrument, which observes photons scattered by nitrogen, oxygen, and other aerosols. Absorption is also measured from ozone and other atmospheric trace gases. Other examples of limb scattering instruments include OSIRIS, which was the first instrument to routinely gather ozone retrieval data, and the SME instrument, also measuring ozone~\citep{OSIRIS}~\citep{SME}.

\subsubsection{Limb Emission}
Limb emission instruments measure radiation emitted by the atmosphere, either thermally or photochemically, along the instrument line of sight (LOS). These are generally long signal level emissions, but can be measured with sensitive instruments. Variation of the line of sight or a wide FOV allows altitude-resolved measurements from clouds in the troposphere up through the thermosphere. Limb emission focuses on the 2.5\textmu m region and above, as the Planck function is very low for wavelengths any shorter than this at the temperatures expected in the atmosphere. In this range atmospheric scattering will not have an affect, however are affected by clouds, and as such cannot go below cloud level. However, a large advantage to this method is the ability to take measurements both at day and night. As no direct illumination source is needed as in other methods, a very dense spatial coverage can be created if the instrument is on a satellite platform. The viewing angle can also be freely chosen as long as it does not directly look at the sun, but this angle must be known exactly to prevent any propagation errors in the data~\citep{IR_limb_emission_measurements}~\citep{SPARC}.

Many early instruments to use this method were low-Earth-orbit instruments that were used to measure vertically resolved profiles of temperature, trace gases, clouds, and aerosols. With many measurements and three-dimensional data chemical structure, these instruments immensely improved understanding of the middle atmosphere region. Instruments such as CRISTA focused on high-spatial resolution, and MIPAS followed with a a focus on high spectral resolution to aquire the most complete set of data in the stratosphere over its decade on-board the ESA satellite Envisat~\cite{GLORIA_objectives}.

This method is of most interest to this thesis, as it is the method used by the LIFE instrument, as well as instruments described below that paved the way for LIFE such as MIPAS and GLORIA. This is chosen for these instruments due to the vertical resolution give by a limb-viewing geometry, as well as the trace gases and constituents that are better detected with limb-viewing thermal emission.

\subsection{Instruments} \label{instruments} %Should I add any other instruments? Or add more to the general paragraph?
There have been a number of instruments that have taken measurements in the UTLS region using a number of different imaging methods, as described in Section \ref{techniques}. However, out of these instruments, two in particular are similar to the LIFE instrument: MIPAS, developed at the University of Karlsruhe in Germany and launched in 2002 aboard the ENVISAT from the European Space Agency, and GLORIA, also developed at the University of Karlsruhe and was flown multiple times on aircraft in the last 10 years~\citep{MIPAS_instrument}~\citep{GLORIA_concept}. These instruments, like LIFE, are thermal emission instruments that use a Fourier transform spectrometer to image the atmosphere. As these instruments lay the foundation for the development of the LIFE instrument, the background and description of each of these instruments are given in this section. An overview of the concept of LIFE is given here as well.

\subsubsection{MIPAS}
A key early instrument to measure limb emission from space is the Michelson Interferometer for Passive Atmospheric Sounding (MIPAS). The reason why it is so important to the field is that it was the first high resolution FTS used for limb emission measurements on-board a satellite. This FTS was used to measure profiles of numerous atmospheric species: H\textsubscript{2}O, O\textsubscript{3}, CH\textsubscript{4}, N\textsubscript{2}O, HNO\textsubscript{3}, and NO\textsubscript{2}, as well as aerosols such as ice clouds. To capture the radiances of these species, MIPAS had a number of spectral ranges: 685-970 cm\textsuperscript{-1}, 1020-1170 cm\textsuperscript{-1}, 1215-1500 cm\textsuperscript{-1}, 1570-750 cm\textsuperscript{-1}, and 1820-2410 cm\textsuperscript{-1}. This spectral range is used as the atmopheric signals are higher in this range to the maximization of the Planck function around 10\textmu m at temperatures in the atmosphere~\citep{MIPAS_instrument}~\citep{MIPAS_conference}.

The main purpose of this instrument is to study dynamics and chemistry from the upper troposphere region all the way to the lower thermosphere. Studying this area of the atmosphere stems from a number of scientific objectives. The first objective is the study of stratospheric chemistry, and specifically the ozone layer. This includes studying the effect of cooling in this region, as a result of ozone depletion and increasing carbon dioxide. Another objective is studying the STE, an important part of the UTLS region as described in Section \ref{UTLS}. Finally, similar to LIFE, it is studying various constituents in the upper troposphere, such as water vapour, for its great importance in climate change. This also includes NO\textsubscript{x} gases and gases moving down from the stratosphere such as ozone. Overall, one of the main goals of this instrument is to observe global changes in the composition of the atmosphere resulting from pollution and other man-made effects throughout its multi-year lifetime~\citep{MIPAS_instrument}.

MIPAS, and similar instruments such as the Atmospheric Chemistry Experiment Fourier Transform Spectrometer (ACE-FTS), utilize Fourier transform spectrometers in their measurements~\citep{SPARC}~\citep{ACE_conference}. However, a limitation of these instruments is that they are not imaging instruments; they have only a single detector pixel. Limb scanning must be used to cover the atmospheric limb, where the instrument moves the line of sight upwards and downwards. However, new and larger data storage and transfer techniques have led to the usage of the imaging Fourier Transform Spectrometer (IFTS), which generates a high amount of data. With a larger throughput, more pixels can be used to create a much wider FOV that covers the atmospheric limb, thus not needing any movement of the instrument. The first instrument to demonstrate the imaging FTS concept for atmospheric measurements is a second generation MIPAS instrument, the Gimballed Limb Observer for Radiance Imaging in the Atmosphere (GLORIA) instrument~\citep{GLORIA_concept}.

\subsubsection{GLORIA}
The GLORIA instrument is an airborne limb imaging instrument operating in the thermal infrared region, similar in concept to MIPAS and LIFE. The instrument was designed to take advantage of two dimensional infrared detector arrays that had become available in the last few decades. This allowed the instrument to overcome one of the primary issues with MIPAS, which was the scanning of the atmosphere with one pixel, as described previously. This two dimensional array also means that three dimensional measurements can be made when using an aircraft and using tomographic techniques. This large array was designed to work with an imaging FTS to provide very high spectral coverage, sensitivity and spectral resolution that no instrument before has managed to achieve. This followed from a need to take measurements in the region of the UTLS, where mission objectives similar to MIPAS and LIFE are to address the gap in data from satellite instruments and airborne instruments of phenomena in this region. This includes the STE, pollutant transport across the region and ozone in both the ozone layer and the upper troposphere. Further mission objectives include measurements of gravity wave propagation in the tropopause, requiring three-dimensional observations of trace gases and temperatures with a high vertical resolution and moderate horizontal resolution~\citep{GLORIA_concept}~\citep{GLORIA_objectives}. 

The instrument consists of a cooled imaging Fourier transform spectrometer with a cryogenic Mercury-Cadmium-Telluride (MCT) two-dimensional detector array for detection of infrared radiation. This is mounted on a gimbal that is mounted to a research aircraft, allowing for free viewing where needed. For calibration, two blackbodies are also mounted on-board, along with the a deep-space view for further calibration~\citep{GLORIA_concept}. GLORIA operates in the region of  780 cm\textsuperscript{-1} to 1400 cm\textsuperscript{-1}, making the detector sensitive to numerous species, including H\textsubscript{2}O, O\textsubscript{3}, CCl\textsubscript{4}, HNO\textsubscript{3}, ClONO\textsubscript{2}, HO\textsubscript{2}NO\textsubscript{2}, and CFCs. The instrument will image from 4 km up to the height of the aircraft, and with its high vertical resolution be able to measure steep gradients in trace gases and characteristics of clouds in this region to help reach its mission objectives. ~\citep{GLORIA_PhD}~\citep{GLORIA_objectives}.

GLORIA can also operate in two different measurements modes, chemistry mode (CM) and dynamics mode (DM). In chemistry mode, spectral resolution is maximized to increase the number of retrieved gas species with a reasonable spatial sampling. Dynamics mode is used to be able to take three dimensional data of species and temperature, with the disadvantage being a lowered spectral resolution. The instrument used both of these measuring modes successfully on multiple airborne flights on the German High Altitude and Long Range research aircraft (HALO)~\citep{GLORIA_concept}. 

\subsubsection{LIFE} %This should be longer, but I don't know where I should get the information from
The LIFE instrument prototype is being developed at the University of Saskatchewan and is designed to build on the success of GLORIA.  A collaboration between the University of Saskatchewan, Canadian Space Agency (CSA), Environment and Climate Change Canada (ECCC) and ABB, it is designed to take high vertical resolution measurements of atmospheric thermal emission over the 7-14 \textmu m spectral range to retrieve key radiative species in the UTLS including H\textsubscript{2}O, HNO\textsubscript{3}, O\textsubscript{3}, N\textsubscript{2}O, and CH\textsubscript{4}. Similar to GLORIA, the goal of LIFE is to fill the gap in information in the UTLS region. LIFE is designed to meet or exceed the capabilities of GLORIA and aims to shrink the complexity of an IFTS atmospheric sensing instrument. The LIFE instrument utilizes a 16-pixel linear array detector to image through an IFTS, to obtain a high vertical resolution of these key species. The instrument was first tested on a high-altitude balloon flight on August 31-September 1, 2019.

\section{Thermal Design}
The thermal environment of a balloon-borne atmospheric instrument is complex, as it goes through a number of stages: It must stay cool in the lab environment, be able to survive ascent through various temperature gradients, thermally remain steady throughout the measurement window in the float portion of the flight, and be able to survive the thermal radiation of sunlight later in the flight as well as the descent. The thermal design of the LIFE instrument, and similar thermal imaging instruments, are of particular importance as the thermal signature of the instrument can have a large affect on the noise of the measurements. As a result of complexity and importance of this problem, the thermal design (with the interconnected mechanical design) of the LIFE instrument is one of the main components of this thesis. 

In this section, a background of thermal design is given that is relevant for thermal imaging balloon borne instruments. Central to thermal design is heat transfer, or the thermal phenomena of radiation, conduction and convection. These are described in detail. Following, the balloon environment is described in more detail, with an example from a previous instrument flight. Self-emission, very important for the design of a thermal-emission imaging instrument, is discussed. The thermal designs of MIPAS and GLORIA, who have similar thermal requirements to LIFE as thermal imaging instruments, are described at the end of this section.

\subsection{Heat Transfer}\label{heat_transfer}
Heat transfer is a very broad topic, covering theoretical physics and engineering physics as well as engineering design. It is covered in many articles, journals, and textbooks. Only a level of background is given here to help understand the thermal phenomena important to thermal analysis, particularly for a balloon-borne atmospheric instrument. At its base, heat transfer is dependent on the Second Law of Thermodynamics: \textit{Heat flows from a hot body to a cold body, increasing the entropy of a closed system}. Heat is a form of measurable energy, discussed in terms of the temperature of bodies. Heat of a material may be related to a number of phenomena, such as atomic or molecular motion of a material, or to electromagnetic radiation~\citep{Heat_Transfer_telescope}.

Heat transfer occurs in three different ways: Radiation, conduction, and convection. These control the flow of heat energy through an object, and each play a different role; radiation emits heat from an object into space, not requiring any outer medium. Conduction defines how heat travels through an object, or a connection between two objects, and convection describes heat moving from an object to a surrounding gaseous medium. Each of these phenomena are described in detail here, to give background for the thermal simulation aspect of this thesis.

\subsubsection{Conduction}
Thermal conduction is the process of heat transfer across solids. This can be done through molecules, atoms, electrons or photons carrying energy. As mentioned previously, the second law of thermodynamics states that heat will always flow from a hot body to a cold body~\citep{Heat_Transfer_Basics}. As a result, thermal conduction will occur in any material where a temperature gradient exists, and as such can play a very important role in thermal design where heat must be moved away from components generating high heat power.

When there is a temperature gradient in a material, there will be heat flux, \textit{q}. Heat flux, also known as thermal flux or heat flux density, is the flow of energy per unit area per unit of time. Most often in units of W/m\textsuperscript{2}, heat flux is used to calculate how much heat is traveling through a medium. Through a body, heat flux is described by \textit{Fourierâ€™s Conduction Law}, shown in Equation \ref{FC_law}.
\begin{equation} \label{FC_law}
    q(T) = -k\nabla T
\end{equation}

Here \textit{k} is the thermal conductivity of the material and $\nabla$\textit{T} is the spacial temperature gradient~\citep{heat_transfer_textbook}. This equation can be used to develop the equation for the heat rate through a surface area:
\begin{equation} \label{heat_rate_conduction}
    Q = \int_{A}q_ndA
\end{equation}
here, $q$ is the same heat flux vector as above, but normal to the surface~\citep{Heat_Transfer_Basics}.

The thermal conductivity is an important aspect of this equation. For an anisotropic material, the conductivity is a tensor and the temperature gradient forms a vector, which makes the Equation \ref{heat_rate_conduction} very difficult to solve. For most designs and technical applications, especially as most materials are isotropic at a macroscopic level, the thermal conductivity can be taken as a mean value. The thermal conductivity is dependent on the material and has units of W/mK~\citep{heat_transfer_textbook}~\citep{FEA_SW}. The design control for the conduction of heat relies on \textit{k}, thus the material chosen. 
% transient conduction could be described here if some more background is needed but probably not necessary.

Another aspect of thermal conduction that must be considered for thermal simulations is boundaries. In many cases, contact between two parts can be simplified to 'bonded' or 'insulated', meaning either full contact as if they were one part, or completely disconnected, respectively. Often parts can be thermally connected using a thermal paste, increasing the contact by as much as 75\%~\citep{Heat_Transfer_Resistance}, making the bonded simplification reasonably accurate. However, in the cases of junctions with a large surface area where thermal paste is not applied, this must be examined more carefully. Instead of a smooth temperature gradient across the connection, there can be a discontinuity, due to the surfaces not being perfectly connected. This is known as \textit{thermal contact resistance}. 

Thermal contact resistance is largely a result of surface roughness. At a joint, there are two main contributions to heat flow: Solid-to-solid conduction at points of contact between the two bodies, and the conduction through entrapped gases in the spaces between contact. Conduction happens easily through direct solid-to-solid contact, but not in gases. These gases are the major cause of thermal contact resistance, as the thermal conductivity of gases is very small as compared to solids and particularly metals. This plays an even larger role in the atmospheric environment, where vacuum means that there are no gases to transfer heat, so the thermal resistance is larger~\citep{Heat_Transfer_Resistance}. 

An equation for heat conduction across a joint can be developed, leading to an equation for solving for $h_c$, known as the contact coefficient. This contact coefficient determines how well heat flows across a joint. If the contact area of a junction is denoted by $A_c$ and the void area by $A_v$, the equation for heat flow across a joint is given by Equation \ref{heat_flow_joint}. % could provide a bit more background on this equation if needed

\begin{equation}\label{heat_flow_joint}
    q = \frac{T_1 - T_2}{\frac{L_g}{2k_1A_c}+\frac{L_g}{2k_2A_c}}+k_fA_v\frac{T_1-T_2}{L_g} = \frac{T_1-T_2}{\frac{1}{h_cA}}
\end{equation}

In this equation $T_1$ is the temperature of the first body, $T_2$ is the temperature of the second body, $k_1$ is the thermal conductivity of the first body, $k_2$ is the thermal conductivity of the second body, $L_g$ is the thickness of the void space between bodies, $k_f$ is the thermal conductivity of the fluid filling this void space, and $A$ is the total area that should be in contact between the two bodies (at a macro scale). $1/h_cA$ is the thermal contact resistance. The left side of this equation is the heat flow due to the solid conduction plus the heat flow due to the fluid conduction, and the right side is the full heat flow~\citep{Heat_Transfer_Resistance}. From these equations the contact coefficient $h_c$ can be solved for, to obtain Equation \ref{contact_coeff_eq}.

\begin{equation}\label{contact_coeff_eq}
    h_c = \frac{1}{L_g}\left( \frac{A_c}{A}\frac{2k_1k_2}{k_1+k_2}+\frac{A_v}{A}k_f \right)
\end{equation}

This equation can be slightly simplified for a balloon environment (vacuum, hence $k_f$ = 0) as well as the conductivity of the materials being equal, shown in Equation \ref{contact_coeff_eq_simplified}.

\begin{equation}\label{contact_coeff_eq_simplified}
    h_c = \frac{A_c}{A}\frac{k}{L_g}
\end{equation}

From the above equation, it appears that the contact coefficient could be calculated rather simply. However, it is extremely difficult to find an accurate value for either the contact area or the size of the gap between parts. There is no theory or even empirical evidence that is reliable. This is to be expected due to the high amount of variables, mainly surface area of a material, which cannot be accurately quantified. The most accurate way of finding this is often through providing a rough estimate, building, and testing the joint in a thermal vacuum chamber. This was done with the LIFE instrument. Further analysis for the thermal resistance in the case of LIFE is described in Chapter \ref{thermal}.

In a vacuum environment, conduction is one of two forms of heat transfer, due to the lack of convection. Thus it is more important to take this into account for any electronics or instruments operating in a vacuum environment, such as an atmospheric instrument. Heat must be able to flow between parts in order to dump heat properly, or else they will overheat. A good contact between all parts is essential to an operational instrument. The only other method of heat transfer in this environment is through radiation. 

\subsubsection{Radiation}
Thermal radiation is heat transfer carried by electromagnetic waves, in the wavelength range of 0.1-1000 \textmu m. As electromagnetic waves do not require any medium to travel, thermal radiation does not require a medium to move through. As such, radiation occurs in vacuum, and with the absence of convection in a vacuum due to the need of a medium, it plays an important role in these environments~\citep{Heat_Transfer_Basics}. Radiation can often be neglected, but in a vacuum environment and at higher temperatures it must be included in the thermal design process.

The intensity of the energy flux radiated from the body is dependent on the temperature of the surface, and increases with temperature. In addition to temperature, the radiation from a surface depends on its emissivity {\textepsilon} - a characteristic of the material or coating of a material. A blackbody is an object that has a very high emissivity, and an ideal blackbody has an emissivity of 1, meaning that it can emit electromagnetic waves at any temperature with maximum intensity. For a typical blackbody, the emissivity is equal to its absorptivity {\textalpha} - or how much radiation is absorbed by the surface. This is why they are known as blackbodies, and whitebodies would absorb no radiation, with an absorptivity of zero. In reality, all surfaces and materials are somewhere in between these two extremes, and are known as greybodies~\citep{Heat_Transfer_Basics}~\citep{heat_transfer_textbook}. The material or coating, and thus the emissivity, must be taken into account in thermal design and is a method of controlling the thermal design to allow the object to emit more or less heat.

It is possible to make an almost perfect blackbody ({\textepsilon} {\textgreater} 0.99), which is often used for calibrating instruments to precise temperatures. A common device is known as a \textit{hohlraum}, German for "hollow space". It is a hollow cylinder or sphere with an opening, with an interior coated with an extremely high emissivity black coating. The interior of the coating is designed to have some sort of rough surface (such as pyramidal structures). With this setup, radiation enters the opening and is almost entirely absorbed by the coating. The parts that do not get absorbed are reflected from the rough surface to another part of the cylinder, where it is absorbed further. In this way, almost all radiation is absorbed, allowing the temperature of the surface to be very clearly and accurately seen by an infrared detector~\citep{Heat_Transfer_Basics}~\citep{heat_transfer_textbook}. An example diagram of this device can be seen in Figure \ref{fig:blackbody_example}. This sort of device plays an important role in LIFE and similar thermal imaging instruments for calibrating the detector at various temperatures.

 \begin{figure}
\centering
  \includegraphics[width=\linewidth]{chap2_images/blackbody_example.JPG}
  \caption{Example of a near-perfect blackbody, known as a \textit{hohlraum}. This is a cross-section of a cylindrical system similar to what is used on the LIFE instrument.}
  \label{fig:blackbody_example}
\end{figure}

The spectral intensity of the radiation emitted from an ideal blackbody surface can be calculated, and is given by Planck's radiation law, in Equation \ref{plancks_law}.

\begin{equation}\label{plancks_law}
    L_{\lambda}(\lambda) = \frac{2hc^2}{\lambda^5}\cdot\frac{1}{e^{(\frac{hc}{\lambda k_B T})}-1}
\end{equation}

Here $h$ is Planck's constant, $c$ is the speed of light, $\lambda$ is the wavelength of incoming radiation, $k_B$ is the Boltzmann constant ($1.38\cdot 10^{-23}$ J/K), and T is the blackbody temperature~\citep{Heat_Transfer_Basics}. This equation gives the Planck curve of the radiation emitted from an object, and is important to the calibration of thermal imaging instruments. This equation is used when calculating spectral radiances for the LIFE detector responsivity, discussed in Chapter \ref{detector}. It units are $Wm^{-2}sr^{-1}$.

The energy emitted from the blackbody surface reaches a theoretical maximum due to the emissivity of 1, and this maximum is given by the Stefan-Boltzmann Law. This law is calculated by the integration of wavelength of Equation \ref{plancks_law} from zero to infinite wavelength~\citep{Heat_Transfer_Basics}. This equation, which gives the flux of energy radiation for a blackbody $q_b$ in $W/m^2$, is shown in Equation \ref{SB_law}.

\begin{equation} \label{SB_law}
    q_b(T) = \sigma T^{4}
\end{equation}

where the Stefan-Boltzmann constant, \textsigma, is $5.67\cdot10^8$ W/m\textsuperscript{2}K\textsuperscript{4} (equal to all constants left from integration), {\textepsilon} is the emissivity of the surface, and \textit{T} is the absolute temperature. For non-blackbodies, the heat flux emitted is the blackbody heat flux multiplied by the emissivity. The total energy radiated can also be shown by multiplying by the area, $A$. Thus the Stefan-Boltzmann Law equation for general surfaces is given below as Equation \ref{SB_law_general}~\citep{Heat_Transfer_Basics}.

\begin{equation} \label{SB_law_general}
    q(T) = \epsilon \sigma T^{4} A
\end{equation}

In most designs, radiation from one surface will intersect with objects in its surroundings. Equation \ref{SB_law} and \ref{SB_law_general} both assume the radiated energy is absorbed by the medium or far surroundings, thus having no affect on the emitting object. In reality, an object emitting energy will have energy emitted to it by a nearby body. The Stefan-Boltzmann Law must be altered for this scenario.

The simplest form of this problem is that all radiation from a blackbody object, say object 1, is absorbed by another blackbody object, say object 2. Likewise, all radiation from object 2 is radiated to object 1 and absorbed. The net heat transferred from object 1 to object 2, known as $Q_{net}$, is the difference of the radiation from object 1 to object 2 and the radiation from object 2 to 1~\citep{heat_transfer_textbook}. This is shown in Equation \ref{SB_surroundings}.

\begin{equation}\label{SB_surroundings}
    Q_{net} = A_1 q_b (T_1) - A_1 q_b (T_2) = A_1 \sigma (T_1^4 - T_2^4)
\end{equation}

Here, $T_1$ is the temperature of the first object, $T_2$ is the temperature of the second object, $A_1$ is the area of the first object, $q_b$ is the heat flux emitted from the first object, and {\textsigma} is the Stefan-Bolztmann constant. Theoretically, this often is good enough. However, for thermal simulations, the more realistic scenario is that the objects see other objects too, and not all radiation from one object is absorbed by one other object. To account for this, a view factor $F_{1-2}$ must be included in the equation. Essentially, this view factor is how well the surface 'sees' the other surface~\citep{heat_transfer_textbook}~\citep{FEA_SW}. Assuming two small areas $A_1$ and $A_2$, the view factor can be calculated using Equation \ref{view_factor}.

\begin{equation}\label{view_factor}
    F_{1-2} = \frac{1}{A_1} \Int_{A_1} \Int_{A_2} \frac{cos \theta_1 cos \theta_2}{\pi R_{1-2}^2} \,dA_1\,dA_2
\end{equation}

Here, $\theta_1$ and $\theta_2$ are the angles between unit normals for each area, and $R_{ij}$ is the line connecting the two areas. This equation is inserted into Equation \ref{SB_surroundings} with the surface emissivity to create Lambert's Law, giving the heat flow rate between two gray diffuse surfaces, shown in Equation \ref{Lamberts_Law}.

\begin{equation}\label{Lamberts_Law}
    Q_{net} = \epsilon A_1 \sigma F_{1-2} (T_1^4 - T_2^4)
\end{equation}

This question assumes the surfaces have the same emissivity. If they have different values, this equation becomes more complex.

As discussed in Section \ref{FEA}, a thermal simulation often breaks a surface into many small surfaces to be able to run the simulation. As such, this equation, particularly the complex Equation \ref{view_factor}, must be solved hundreds of thousands of times for each simulation. As such, it requires major computational power to run simulations that include surface-to-surface emissivity. For the purpose of saving time in simulations, this is often approximated by estimating the ambient temperature an object will see when radiating, along with an estimated view factor, and changing if necessary. This will make simulations less accurate but many more simulations are able to be run, so these settings can be altered with trial and error until they are deemed accurate.

 In relation to the thermal design, which is discussed in detail in Chapter \ref{thermal}, the two main variables that can be altered when running simulations and testing designs are the surface area and emissivity. Choosing the right material to either maintain or emit heat through radiation to stop freezing or overheating, as well as designing to allow heat to be dumped to less heat-sensitive parts of the instrument through conductivity, are critical parts of thermal design.

\subsubsection{Convection}
For most of the LIFE thermal simulations, convection does not play a part. This is because at the altitude LIFE floats at, roughly 30-35km, there is essentially a vacuum. There is no medium for convection to act in, thus it is not considered in the simulations. However, after the LIFE flight, the ascent was simulated, and convection still played a part in this aspect of the flight, especially through the cold tropopause. As such, and as it often plays an extremely important role in thermal design, it is discussed here. However, convection is more complex than the previous to methods of heat transfer, due to the involvement of fluid dynamics, and is a very in-depth topic. It will only be discussed here at a high level.

Convection, particularly forced-convection, occurs when a cool fluid flows past a warm body, carrying away heat from the body. The air closest to the body forms a boundary layer, where the moving air is slow. In this region, conduction moves heat from the body to the fluid. The fluid then carries away this heat downstream, and in this way the heat from the body is constantly being stripped away~\citep{heat_transfer_textbook}.

Cooling through the convective process can be described by a simple formula, originally developed by Newton. If the energy of a body is constantly replenished, and the temperature of the oncoming fluid remains constant, the heat removed by the convective fluid is proportional to the difference of the object temperature and the fluid temperature. This equation can be written to solve for the heat flux from the object, shown in Equation \ref{newtons_equation}.

\begin{equation}\label{newtons_equation}
    q = \bar{h}(T_{body} - T_{\infty})
\end{equation}

This is known as Newton's law of cooling in the steady state, and here $T_{body}$ is the temperature of the body, $T_{\infty}$ is the temperature of the fluid, and $\bar{h}$ is the average heat transfer coefficient. The units of $q$ are W/m\textsuperscript{2} as usual with heat flux, so the units of $\bar{h}$ are W/m\textsuperscript{2}K~\citep{heat_transfer_textbook}.

An issue with simulating convection is this heat transfer coefficient; it is very difficult to find an accurate value for $bar{h}$, as it is dependent on a large number of variables. Firstly, it is is sometimes dependent on $(T_{body} - T_{\infty})$, or $\Delta T$. This dependence is based on if fluid is forced past a body, known as \textit{forced convection}, or if the fluid is still, known as \textit{free} or \textit{natural convection}. If $\Delta T$ is small, there is a negligible dependence, but can have a large effect (up to $\Delta T^2$) if the temperature difference is large. Natural convection, which behaves differently than forced convection as it is more dependent on the heat from the object causing air to rise (and thus bringing colder air back down against the object, causing a cycle). This leads to a small dependence on $\Delta T$, on the order to $\Delta T^{1/3}$. In addition to these dependencies, it is dependent on pressure through the Reynolds number (used through fluid turbulence calculations near the object surface), the material and its conductivity, and the material surface and shape~\citep{heat_transfer_textbook}.

Due to this large variety of unknowns, it is quite complex to calculate the heat transfer coefficient, even for just one scenario, which can change quickly. Values of $\bar{h}$ for one scenario (for forced convection over an aluminum surface, for example) can vary over 6 orders of magnitude, causing massive changes to the simulation~\citep{heat_transfer_textbook}. It is recognized that this is one of the largest unknowns with the thermal design and simulations, as a result.

If a heat transfer coefficient is known, Equation \ref{newtons_equation} can estimate the heat flux reasonably well, enough for our thermal simulation purposes. Much theory surrounding convection is solving to find the heat transfer coefficient, and even then still have a large amount of error, and solving equations related to the boundary layer. For the purposes of the LIFE thermal simulations, and considering that convection plays a role in only a small portion of the flight, these equations will not be described. In the simulations, as described in Chapter \ref{thermal}, a heat transfer coefficient is chosen out of an estimated range from literature, and iterated through multiple simulations, as is often the most practical way of finding the coefficient. 

\subsection{Balloon Environment} % could maybe use more if anything can be thought of
Thermal design is a crucial part of atmospheric instruments, and particularly thermal imaging instruments. The thermal environment seen by these instruments varies widely, in a number of different scenarios: In the lab on the ground, during the ascent, during float, both with and without the sun. For example, when a balloon-borne instrument is travelling upwards through the tropopause, where the temperature reaches extreme temperatures such as -80Â°C, the temperature of the instrument can drop very rapidly by tens of degrees. When working with delicate imaging instruments and thermal imaging instruments where the temperature can affect measurements, it is important that this is taken into account during design.

On the ground, most instruments are cooled with a combination of conduction and convection. Convection often plays a large role by using fans to cool the instrument. However, at high altitudes, the pressure is very low and can be considered vacuum. As described in Section \ref{heat_transfer}, convection requires a medium to move heat away to cooler areas. Without any fluid, heat is only transferred through conduction and radiation. Convection will play a role during ascent, as the air is still thick enough in the lower troposphere to have an affect, but decreases rapidly. This lends complexity to the thermal design, as there is little information on how the convection coefficient changes at higher altitudes. 

If the instrument is not flying overnight, the sun will have a large affect on heating at these altitudes. The solar flux is the heat transferred to an object from the sun. The atmosphere lowers this flux by attenuation, so that it is not as intense at ground level. In the lower stratosphere where the instrument will sit for the majority of its flight, the sun can be extremely intense and can heat the instrument very quickly if no shielding is provided. It should be known if the sun will be seen during the balloon flight of an instrument so it can be shielded and able to dump heat accordingly.

Due to the extreme variation in temperatures that the instrument will see from the ascent through the tropopause to the sun, it is helpful to have data on what can be expected. Data is provided from a previous atmospheric balloon-borne instrument from the University of Saskatchewan, launched from the same location as LIFE in Timmins, Ontario. This data was measured throughout the flight in August of 2018 by the National Centre for Space Studies (CNES), who operated the balloon. This data is shown in Figure \ref{fig:2018_timmins_temps}, which provides data for numerous temperature sensors scattered around the balloon gondola~\citep{CATS_report}.
 
 \begin{figure}[h]
\centering
  \includegraphics{chap2_images/CNES_temps_CATS_2018.png}
  \caption{High altitude balloon temperatures during 2018 flight in Timmins, Ontario}
  \label{fig:2018_timmins_temps}
\end{figure}

It can be seen in Figure \ref{fig:2018_timmins_temps} that the lowest gondola temperature reached during the flight was -40Â°C, while travelling through the tropopause. Of note in this region is the sharp decrease in temperature throughout this region, in a matter of minutes. The thermal shock of this temperature decrease in this region must be considered for delicate electronic components and optics. Temperatures for thermal simulation scenarios were chosen based on what was seen here, which is described further in Chapter \ref{thermal}.

Atmospheric instruments often have delicate optics or electronics, so the thermal characteristics of the instrument are a very important part of the design. Particularly for thermal imaging instruments, the optics must be carefully controlled in order to reduce the thermal radiation background, or self-emission, effect on measurements. Self-emission can lead to systematic error in the data, as part of the data collected are thermal properties from the optics rather than the atmosphere. This is gone over in further detail in Section \ref{self-emission}. Various instruments use different methods to maintain appropriate operational conditions for the instrument. The MIPAS and GLORIA thermal designs are discussed in Section \ref{GLORIA_MIPAS_thermal} for context. 

\subsection{Self-Emission}\label{self-emission}
Discuss self-emission at a deep background level, similar to what Jeff and I talked about and what Ethan has been looking into. Don't discuss the design of LIFE at all that allowed us to ignore this more than most instruments.

[TODO]

\subsection{Instruments} \label{GLORIA_MIPAS_thermal}
Summarize thermal designs of previous instruments. Part of this is described above in the balloon environment opening.

\subsubsection{MIPAS}
The MIPAS instrument used an FTS for the detection of limb emission spectra. To avoid self-emission from the FTS, it was cooled and maintained at 210K. The optics and detector of MIPAS were also actively cooled and kept below 70K to reduce both thermal emission and internal noise contribution. Cooling for components required the use of multiple Stirling coolers and good thermal insulation. All optics were fully thermally isolated from the rest of the instrument which led to a complex optical design~\citep{MIPAS_instrument}.

\subsubsection{GLORIA}
The GLORIA instrument similarly uses a cooled FTS system. The desired operating range of the lens and FTS system is 200-220K, to again self-emission and resulting noise. To maintain this low temperature while operating on an aircraft, a complex system was designed that uses liquid carbon dioxide. This CO\textsubscript{2} is sprayed into a cooler tank under high pressure through small injection pipes, which sharply drops the pressure at the exit. This leads to adiabatic cooling and the generation of CO\textsubscript{2} snow, which keeps the instrument operating at the required temperature for 24 hours. Liquid nitrogen is also a cooling option but this could not be used during flight due to safety and weight constraints and is only used in the lab. To avoid data contamination due to the CO\textsubscript{2}, the FTS is sealed. Around this entire closed system vacuum insulation panels are used. Finally, the detector itself must be cooled to a temperature of 50K, which was accomplished with a Stirling cooler~\citep{GLORIA_concept}~\citep{GLORIA_thermalmech}
% There is a paragraph following this in the advisory report that goes into the LIFE thermal considerations at a similar level. There is not really a good place to put it in this thesis but can be used if necessary.

\section{IR Detectors}
Talk about different types of IR Detectors

\subsection{MCT Detectors}
The detector chosen for use in the LIFE instrument is known as a Mercury Cadmium Telluride (MCT, or HgCdTe) detector. This semiconductor detects photons in the short-, mid-, and long-range infrared regime. Semiconductor characteristics that make this material preferable include long minority carrier lifetime, low carrier concentration, and small effective mass and high mobility~\citep{MCT_Detectors}. Other advantages of this detector include high response and sensitivity to infrared radiation. The GLORIA instrument uses a 2562-pixel MCT detector array~\citep{GLORIA_concept}. A drawback of the high sensitivity of these detectors is to lower noise as much as possible, they must be kept at very low temperatures. As described in Section \ref{GLORIA_MIPAS_thermal}, most detectors including those in GLORIA and LIFE are cooled to 70K or lower. The LIFE MCT detector setup is described in more detail in Chapter \ref{detector}.

\subsection{Non-linearity}
MCT detectors operate via either photovoltaic (PV) cells or photoconductive (PC) cells. PV detectors are used for shorter wavelength applications, whereas PC detectors, such as those used in LIFE, can be used for wavelengths up to 20\textmu m. Photoconductors exhibit a change in conductance when radiant power is applied, and the detector is operated with a constant bias current in order to sense the change in conductance, which is proportional to radiant flux. A voltage change is measured across the detector. An issue that arises is this voltage change across the detector is not linear with incident photon flux. This is due to a variety of reasons, but mainly due to the intrinsic non-linearity of semiconductors and their band gaps, as well as the non-linearity of the voltage as it approaches saturation~\citep{current_measurement_MCTs}~\citep{MCT_linearity}.  This non-linearity may be decreased through characterization of the detector, by changing the bias voltage and the current offset.

\subsection {Responsivity}
In addition to non-linearity, another characteristic of MCT detectors that can be determined and optimized is the responsivity. The detector responsivity is a measure of the sensitivity of the detector to incoming signal. Ideally, the higher the responsivity, the better the performance of the detector~\citep{GLORIA_PhD}. A basic circuit for measuring the responsivity is a circuit consisting of a bias battery supply \textit{V}, a load resistance \textit{R\textsubscript{L}}, and a detector with a dark current \textit{R\textsubscript{0}}. When radiation falls on the detector, the responsivity $\mathcal{R}_s$ given by Equation \ref{responsivity_eq_1}.

\begin{equation} \label{responsivity_eq_1}
    \mathcal{R}_s = \frac{V_s}{\phi h \nu A}
\end{equation}

Here $\phi$ represents the number of photos of frequency $\nu$ incident on detector \textit{A}. In the small signal approximation, the signal voltage \textit{V\textsubscript{s}} of this circuit is given by Equation .

\begin{equation}
    V_s = V \frac{R_L}{(R_L+R_0)^2}(-\Delta R_0)
\end{equation}

Here $\Delta R_0$ is the change in resistance of the detector due to illumination~\citep{MCT_responsivity}. The method of finding the responsivity in the case of LIFE is described in detail in Chapter \ref{detector}.